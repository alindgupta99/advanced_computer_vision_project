png_file_type = '.png'
all_photos_folder_sub_path = 'all_photos'
sketch_augmentation_src_folder_path = "../Data/images/256x256/sketch"
sketch_all_photos_path = "/content/drive/MyDrive/CV_project/Task 1/all_photos"
llava_model_name = "llava-hf/llava-1.5-7b-hf"
llava_model_id = 'llava'
blip2_unprompted_model_id = 'blip2_unprompted_'
blip2_prompted_model_id = 'blip2_prompted_'
blip2_model_name = 'Salesforce/blip2-opt-2.7b'
llava_device_map = 'auto'
blip2_device_map = 'auto'
minivlm_device_map = 'cuda'
image_colour_code = 'RGB'
blip2_max_new_tokens = 50
llava_input_prompt = "<image> Describe what is in this image."
blip2_input_prompt = "this is a picture of"
image_tag = '<image> '
minivlm_input_prompt = "<image> What is this image."
llava_return_tensor = 'pt'
blip2_return_tensor = 'pt'
minivlm_return_tensor = 'pt'
clip_return_tensors = 'pt'
llava_processor_suffix = 'llava_processor'
blip2_processor_suffix = 'blip2_processor'
minivlm_processor_suffix = 'minivlm_processor'
llava_model_suffix = 'llava_model'
blip2_model_suffix = 'blip2_model'
minivlm_model_suffix = 'minivlm_model'
minivlm_model_name = 'sentence-transformers/all-MiniLM-L6-v2'
sketch_metadata_file_path = '/content/drive/MyDrive/CV_project/stats.csv'
sketch_filename_column_id = 'SketchFilename'
imagenet_id_column_id = 'ImageNetID'
sketch_id_column_id = 'SketchID'
worker_tag_column_id = 'WorkerTag'
category_column_id = 'Category'
llava_num_reduced_rows = 25
blip2_num_reduced_rows = 100
hiphen_connector = '-'
has_error_column_id = 'Error?'
has_ambiguity_column_id = 'Ambiguous?'
test_data_frac = 0.2
save_dir_path = 'Outputs'
untrained_model_prefix = 'untrained_'
full_data_model_prefix = 'full_data_'
filtered_data_model_prefix = 'filtered_data_'
reference_captions_key = 'reference_captions'
pixel_values_key = 'pixel_values'
input_ids_key = 'input_ids'
attention_mask_key = 'attention_mask'
image_paths_key = 'image_paths'
generated_captions_key = 'generated_captions'
empty_string = ''
train_batch_size = 1
should_shuffle = True
train_learning_rate = 5e-5
train_num_epochs = 10
bert_score_lan = 'en'
clip_model_name = "openai/clip-vit-base-patch32"
cuda_device = 'cuda'
cpu_device = 'cpu'
write_mode = 'w'
pkl_file_type = '.pkl'
txt_file_type = '.txt'